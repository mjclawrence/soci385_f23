---
title: "Introducing Hypothesis Testing"
date: "October 24, 2023"
author: "Matt Lawrence"
format: html
---

## Setting Up

Load the `gss_week7.csv` file on Canvas as a data frame called `gss_week7` and load the usual packages:

```{r}
#| message: false
#| label: load packages and data

library(tidyverse)
gss_week7 <- read_csv("https://raw.githubusercontent.com/mjclawrence/soci385_f23/main/data/gss_week7.csv")
```


## Comparing The Z and T Distributions

When the population standard deviation is unknown (almost always), the uncertainty of the standard error estimate is addressed by using a new distribution: the t distribution. This distribution also has a bell shape, but its tails are thicker than the normal modelâ€™s.

When the sample size is large, z and t are the same. When in doubt, use t. It will always work since it adjusts for the sample size.

You can find t-values and associated probabilities using functions similar to the `norm()` functions. The difference is that with the `t()` functions you also give the degrees of freedom, which for these tests will equal the sample size - 1.

This is what we did before to get the z-value associated with the 95% confidence interval:

```{r}
#| label: qnorm example

qnorm(.975) 
```

The equivalent code with the t-distribution and a sample size of 1001 (so degrees of freedom or "df" of 1000). 

```{r}
#| label: qt for large sample size

qt(.975, df = 1000)
```

With smaller samples, using the t-distribution builds in extra room since our estimates are less reliable: 

```{r}
#| label: qt for smaller sample size

qt(.975, df = 100)
```

To find the probabilities associated with t-values, use `pt()` which also requires degrees of freedom:

```{r}
#| label: pt for t distribution

pt(1.962339, df = 1000)
```

And 1 - pt() also works the same way as 1 - pnorm():

```{r}
#| label: pt for t distribution with smaller sample

1 - pt(1.983972, df = 100)
```


## Significance Testing

Let's test if the mean value of `childs` in 2018 differed from 2.2 (the 1984 mean, which we get from previous research).

What was the mean for `childs` in 2018?

### REPLACE THIS LINE WITH YOUR CODE CHUNK ###

```{r}
#| label: find mean for sample year

mean(gss_week7$childs[gss_week7$year==2018])
```


The test statistic is calculated as: 
$\Large{t = \frac{y - y_{H0}}{SD/ \sqrt{n}}}$

Let's get the standard deviation, n, and the square root of n:

```{r}
#| label: components of test statistic

sd <- sd(gss_week7$childs[gss_week7$year==2018])
n <- length(gss_week7$childs[gss_week7$year==2018])
sqrt_n <- sqrt(n)
```


For our test, the test statistic is:

```{r}
#| label: calculate test statistic

(1.998255 - 2.2) / (sd/sqrt_n)
```

What is the t-value for the critical region for our sample size and an alpha level of .05?

### REPLACE THIS LINE WITH YOUR CODE ###

```{r}
#| label: find t value for critical region

qt(.025, df = 572)
```

Our test statistic is more extreme than that so we can reject the null hypothesis that the population mean is 2.2.

We could also use the p-value in the hypothesis test. If our p-value is less than the alpha level for our confidence range, we can reject the null hypothesis. 

What is the p-value for our test statistic?

```{r}
#| label: p value for example

pt(-3.389708, df = 572)
```

That's for one side of the curve, so we need to double it for the test:

```{r}
#| label: double the p value

pt(-3.389708, df = 572) * 2
```

We can reject the null hypothesis because the p-value is less than .05 (the cutoff for a 95% test).

## Shortcut!

R has a built-in function called `t.test()` that will calculate all of these test statistics. With one mean, we have to fill in the value of mu ($\mu$) which is the null hypothesis value. If you leave it out, the default is zero.

```{r}
#| label: t test in r

t.test(gss_week7$childs[gss_week7$year==2018], mu = 2.2)
```

For another example, let's look at 2018's mean ideal number of children (variable = `chldidel`). Using `t.test()`, can we reject the null hypothesis that the 2018 mean is the same as 2.55 at the .05 alpha level?

### REPLACE THIS LINE WITH YOUR CODE CHUNK ###

```{r}
#| label: t test in r exercise
t.test(gss_week7$chldidel[gss_week7$year==2018], mu = 2.55)
```

We can change the default level of .05 to .01 using the conf.level option (which requires the confidence level, so .99 for the .01 alpha level). Can we reject the null hypothesis that the 2016 mean is the same as 2.5 at the .01 alpha level? 

```{r}
#| label: t test in r exercise 2

t.test(gss_week7$chldidel[gss_week7$year==2016], mu = 2.5,
       conf.level = .99)
```

# Thursday Warm Up Exercise

Descriptions of all the GSS variables are available at: 

https://gssdataexplorer.norc.org/home

Click the "Search Variables" button and find the description for the `parsol` variable.

What could be a sociological research question using responses to the `parsol` question and the average number of ideal children (the `chldidel`)?


The population average for number of ideal children is 2.58 for respondents who say their standard of living is "Somewhat Better" or "Much Better" than their parents. Does the average for respondents who say "Somewhat Worse" or "Much Worse" significantly differ from that value at the 95% confidence level?

```{r}
t.test(gss_week7$chldidel[str_detect(gss_week7$parsol, "Worse")], mu = 2.58, conf.level = .95)
```





Comparse worse to mean for better?
(If parsol == better, mean chldidel = 2.58)
(If parsol == worse, mean chldide = 2.49)


# Inference For Single Proportions

We have previously seen that proportions and means have different standard errors. As a result, we use different hypothesis tests for them as well. We'll skip to the shortcut this time. 

Example: Does the proportion of respondents whose number of children is equal to their ideal number of children differ from .33? 

First let's create a binary variable identifying respondents whose number of children is equal to their ideal number of children with a 1 and everyone else with a 0.

```{r}
#| label: create binary variable

gss_week7 <- gss_week7 |> 
  mutate(has_ideal = ifelse(childs == chldidel, 1, 0))
```

For the test, we will need the frequency with a 1 and the total in the sample.

```{r}
#| label: addmargins to get table total

addmargins(table(gss_week7$has_ideal))
```

Enter those two values in `prop.test()` along with the null hypothesis value you want to test. The function calculates the proportion and compares it to the null hypothesis value.

```{r}
#| label: prop.test example

prop.test(889, 2923, p = .33)
```

The prop.test function doesn't use the t-distribution so the test statistic is different (and cannot be compared to 1.96). But the p-value can still be compared to the alpha level and you can still compare the null hypothesis value to your confidence interval.

In the example above, can we reject the null hypothesis that the proportion differs from .33? 

Another example: Does the proportion of respondents with less children than their ideal number differ from .53 at the 99% confidence level?

### REPLACE THIS LINE WITH YOUR CODE CHUNK ###

```{r}
#| label: prop.test example 2 binary variable

gss_week7 <- gss_week7 |> 
  mutate(less_ideal = ifelse(childs < chldidel, 1, 0))
```

```{r}
#| label: prop.test example 2 frequencies
addmargins(table(gss_week7$less_ideal))
```

```{r}
#| label: prop.test example 2 results

prop.test(1486, 2923, p = .53, conf.level = .99)
```
