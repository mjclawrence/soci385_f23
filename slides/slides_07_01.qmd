---
title: "Social Statistics"
subtitle: "Introducing Hypothesis Testing"
date: "October 24, 2023"
format: 
  clean-revealjs:
    incremental: true
    progress: false
    slide-number: false
    controls: auto
    menu: 
      side: left
---

## Introducing Significance Testing

- Confidence Intervals: Based on our sample estimate and confidence level, what is the range of possible values for population parameter?

- Shift to significance: How unusual - how unlikely - is our sample estimate?

- More specifically: What is the probability (.1, .05, .01, etc.) of getting a value at least as extreme as our estimate?

- Can we be confident at a certain level of probability that the difference between our estimate and another value is *statistically significant*, meaning not just from random chance?

---

## Parts of the Significance Test

- Assumptions: Random, Normal, Large, Increasing Validity

- Build two hypotheses covering the entire range

- Null Hypothesis: What we are testing *against* 
  - Null is usually 0 but can be any value
  - $H_0: \hat{\mu} = 0$ 

- Alternative Hypothesis: What we estimate from our data
  - Estimated mean is not 0
  - $H_A: \hat{\mu} \neq 0$ 

---

## Parts of the Significance Test

- Compute a test statistic for our estimate

- Previously we wanted distance from the mean in SDs
  - That formula: $\Large{z = \frac{x-\mu}{\sigma}}$

- Now we want distance from the null hypothesis' value in SEs
  - This formula: $\Large{t = \frac{\mu_x - \mu_0}{SD_x / \sqrt{n}}}$
  - t adjusts for *degrees of freedom*
  - Denominator = standard error
  - Fill in $\mu_0$ from null hypothesis (0)

---

## From Z to T

- When the population standard deviation is unknown (almost always), the uncertainty of the standard error estimate is addressed by using a new distribution: the t distribution.

- This distribution also has a bell shape, but its tails are thicker than the normal modelâ€™s

- Therefore observations are more likely to fall beyond two SDs from the mean than under the normal distribution

- These extra thick tails are also helpful for resolving our problem with a less reliable estimate and a bigger standard error (if n is small)

---

## From Z to T
![](385_figures/t_normal.png)

---

## From Z to T

- When the sample size is big enough, z and t are the same.

- When in doubt, use t and assert the degrees of freedom. It will always work.

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

qnorm(.975)
```

:::

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

qt(.975, df = 1000)
```

:::

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

qt(.975, df = 100)
```

:::

---

## From Z to T

- Other `norm()` functions also work with `t()`:

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

pt(1.962339, df = 1000)
```

:::

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

1 - pt(1.983972, df = 100)
```

:::

---

## Back to the Significance Test

- Calculate the test statistic, and convert it to a probability (a p-value) using `pt()` if negative or `1 - pt()` if positive.
  - Multiply this probability by two to get the probability for each tail.

- That p-value is probability of observing a value of the test statistic at least as extreme as the absolute value of our estimate
  - A smaller p-value presents stronger evidence against $H_0$.
  - Careful: not the probability that the null hypothesis is true

---

## Parts of the Significance Test

- Choose significance level
  - Alpha $\alpha$ is significance level, or level of uncertainty, against which we want to evaluate the test statistic
  - Also known as rejection region or critical region

- We will reject the null hypothesis if test statistic falls within this rejection/critical region

- But we will not *accept* the null hypothesis if test statistic falls outside this region

- Described in terms of probability of being *beyond* the range of values that are more likely, so we say .05 rather than .95

---

## Critical Region


![](385_figures/critical_region.png)

---

## Significance Test for Mean - Example

- Imagine we want to test if the average number of children a GSS respondent has in 2018 is different from the average from 1984. Why might we expect people have different numbers of children in these two periods?

- Using `gss_week7.csv` file on Canvas, let's test if the mean value of `childs` in 2018 differed from the 1984 mean of 2.2 (which we know from previous research).

- What was the mean for `childs` in 2018?

::: {.fragment}

```{r}
#| echo: false
#| message: false

library(tidyverse)

gss_week7 <- read_csv("https://raw.githubusercontent.com/mjclawrence/soci385_f23/main/data/gss_week7.csv")
```

:::

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

mean(gss_week7$childs[gss_week7$year==2018])
```

:::

---

## Significance Test for Mean - Example

- Null Hypothesis = Actual mean is 2.2 (filled in from 1984)

- Alternative Hypothesis = Actual mean is *not* 2.2
  - Note, if alternative were that the mean is a specific number (like 2), hypotheses would not cover entire range!

- Significance level = .05

---

## Significance Test for Mean - Example

- $\Large{t = \frac{y - y_{H0}}{SD/ \sqrt{n}}}$

- $\Large{t = \frac{1.998 - 2.2}{0.05951692}}$

- $\Large{t = -3.389708}$

- In words: sample mean of 1.998 is 3.39 *standard errors* below the null hypothesis value.

---

## Significance Test for Mean - Example

- What is the t-value for the critical region for our sample size and an alpha level of .05?

- There are 573 observations in the 2018 sample, so we use 572 for the degrees of freedom

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

qt(.975, df = 572)
```

:::

---

## Significance Test for Mean - Example

- For mean to be significant at .05 level, the test statistic needs to be at least +/- 1.96412 or standard errors away. Our test statistic of -3.39 is more extreme than -1.96412, so we can reject the null hypothesis that the mean number of children in 2018 does not differ from 2.2. 

- In other words, the average number of ideal children in 2018 is significantly lower than the average number of ideal children in 1984. There has been a statistically significant decline in number of ideal children during that period.

---

## Significance Test for Mean - Example

- We would reach the same conclusion using p-values. The test statistic of 3.39 is negative, so we can use `pt()` instead of `1 - pt()`:

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment
pt(-3.39, df = 572)
```

:::

- Multiply this value by two (or both sides of distribution)

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

2 * 0.0003735504
```

:::

- The p-value for our hypothesis test is less than .05, so we can reject the null hypothesis.

---

## Significance Test for Mean - Example

- We would also reach the same conclusion using confidence intervals.

::: {.fragment}

```{r}
#| echo: false
#| output-location: fragment

idealchilds_ci <- c(1.881356, 1.998255, 2.115153)
```

:::

::: {.fragment}

```{r}
#| echo: false
#| output-location: fragment

idealchilds_ci
```

:::

- The null hypothesis value of 2.2 falls outside our confidence interval, so we can reject the null hypothesis.

---

## Big Shortcut: t.test()

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

t.test(gss_week7$childs[gss_week7$year==2018], 
      mu = 2.2)
```

:::

---

## Significance Test for Mean - Example

![](385_figures/ttest_childs_example.png)
- Red box gives the test statistic. Blue box gives the probability of getting a value more extreme than the test statistic. Green box is the 95% confidence interval. Orange box gives the sample mean. 

---

## Exercise

- Let's look at 2018's mean ideal number of children (variable = `chldidel`)

- Using `t.test()`, can we reject the null hypothesis that the 2018 mean is the same as the 1990 mean of 2.55 at the .05 alpha level?

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

t.test(gss_week7$chldidel[gss_week7$year==2018], 
      mu = 2.55)
```

:::

---

## Significance Test for Mean - Exercise

- No, do not reject the null hypothesis:
  - The test statistic is not more extreme than -1.97
  - The p-value is greater than .05
  - The confidence interval does include null hypothesis value of 2.55

---

## Other t.test() Options

- Can we reject the null hypothesis that the 2016 mean is the same as 2.5 at the .01 alpha level? We can change the default level of .05 to .01 using the conf.level option (which requires the confidence level, so .99 for the .01 alpha level).

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

# To Change Confidence Level:

t.test(gss_week7$chldidel[gss_week7$year==2016], 
      mu = 2.5, conf.level = .99)
```

:::

---

## Other t.test() Options

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

# To Change Confidence Level:

t.test(gss_week7$chldidel[gss_week7$year==2016], 
      mu = 2.5, conf.level = .99)
```

:::

---

## Enough For Today?

---

## Inference For Single Proportions

- Means and proportions have different distributions, standard errors and hypothesis tests.

- For proportions, we'll use `prop.test()` rather than `t.test()`.

- Example: Does the proportion of respondents whose number of children is equal to their ideal number of children differ from .33?

---

## Inference For Single Proportions

- First step, create binary variable capturing respondents whose number of children is equal to their ideal number of children. Call it `has_ideal`.

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

gss_week7 <- gss_week7 |> 
  mutate(has_ideal = ifelse(childs == chldidel, 1, 0))
```

:::

---

## Inference For Single Proportions

- For the test, we will need the frequency with a 1 and the total in the sample.

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

addmargins(table(gss_week7$has_ideal))
```

:::

---

## Inference For Single Proportions

- Enter those two values in `prop.test()` along with the null hypothesis value you want to test. The function calculates the proportion and compares it to the null hypothesis value.

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

prop.test(889, 2923, p = .33)
```

:::

---

## Another Example

Does the proportion of respondents with less children than their ideal number differ from .53 at the 99% confidence level?

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

gss_week7 <- gss_week7 |> 
  mutate(less_ideal = ifelse(childs < chldidel, 1, 0))
```

::: 

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

addmargins(table(gss_week7$less_ideal))
```

:::

---

## Another Example

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

prop.test(1486, 2923, p = .53, conf.level = .99)
```

:::