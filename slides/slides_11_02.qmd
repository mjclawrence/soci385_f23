---
title: "Social Statistics"
subtitle: "Interactions"
date: "November 30, 2023"
format: 
  clean-revealjs:
    incremental: true
    progress: false
    slide-number: false
    controls: auto
    menu: 
      side: left
---


```{r}
#| echo: false
#| message: false

library(tidyverse)
library(kableExtra)
midd_survey <- read.csv("https://raw.githubusercontent.com/mjclawrence/soci385_f23/main/data/midd_survey.csv")
```

## Warm Up: midd_survey.csv

- Everyone: regress gpa on number of siblings 

- Group 1: Add control for gender to original model
  - Predict gpa for men with 3 siblings and women with 4 siblings

- Group 2: Add control for class to original model
  - Predict gpa for middle class student with 2 siblings and upper middle class student with 1 sibling

- Group 3: Add controls for gender and class to original model
  - Predict gpa for lower class men with 0 siblings

---

## Warm Up - Original Model

### Regress gpa on number of siblings

::: {.fragment}

```{r}
#| echo: true
#| output: false

gpa_sibs_model <- lm(gpa ~ siblings, 
  data = midd_survey)

summary(gpa_sibs_model)
```

:::

---

## Warm Up - Original Model

```{r}
summary(gpa_sibs_model)
```


---

## Warm Up - Original Model

```{r}
gpa_sibs_plot <- ggplot(midd_survey, aes(x = siblings, y = gpa))
gpa_sibs_plot + geom_point() + geom_abline(intercept = 3.558767,
                                           slope = -0.031819) +
     labs(x = "Number of Siblings", y = "GPA", title = "GPA and Number of Siblings", subtitle = "Professor Peggy Nelson's Middlebury Survey") + 
     theme(axis.title = element_text(size = 18), axis.text = element_text(size = 16),
      plot.title = element_text(size = 18), plot.subtitle = element_text(size = 14))
```

---

## Warm Up 1

### Regress gpa on number of siblings, controlling for gender

::: {.fragment}

```{r}
#| echo: true
#| output: false

gpa_sibs_gender_model <- lm(gpa ~ siblings + gender, 
      data = midd_survey)

summary(gpa_sibs_gender_model)
```

:::

---

## Warm Up 1

```{r}
summary(gpa_sibs_gender_model)
```

---

## Warm Up 1

### Predict gpa for men with 3 siblings and women with 4 siblings

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

# For Men With 3 Siblings:
3.531540 - .031269*3
```

:::

<br>

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

# For Women With 4 Siblings:
3.531540 - .031269*4 + .045629
```

:::

---

## Warm Up 1

```{r}
gpa_sibs_plot + geom_point(color = "Light Gray") + 
     geom_abline(intercept = 3.531540, slope = -0.031269, color = "Red") +
     geom_abline(intercept = 3.531540-0.058342, slope = -0.031269, color = "Purple") +
     geom_abline(intercept = 3.531540+0.045629, slope = -0.031269, color = "Forest Green") +
     geom_text(x = 2.5, y = 3.875, label = "Women", color = "Forest Green", size = 10) +
     geom_text(x = 2.5, y = 3.75, label = "Men", color = "Red", size = 10) +
     geom_text(x = 2.5, y = 3.625, label = "Other", color = "Purple", size = 10) +
     labs(x = "Number of Siblings", y = "GPA", title = "GPA and Number of Siblings", subtitle = "Professor Peggy Nelson's Middlebury Survey") + 
     theme(axis.title = element_text(size = 18), axis.text = element_text(size = 16),
      plot.title = element_text(size = 18), plot.subtitle = element_text(size = 14))
```

---

## Warm Up 2

### Regress gpa on number of siblings, controlling for class.

::: {.fragment}

```{r}
#| echo: true
#| output: false

gpa_sibs_class_model <- lm(gpa ~ siblings + class, 
  data = midd_survey)

summary(gpa_sibs_class_model)
```

:::

---

## Warm Up 2

```{r}
summary(gpa_sibs_class_model)
```

---

## Warm Up 2

### Predict gpa for middle class student with 2 siblings and upper middle class student with 1 sibling

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

# For middle class student with 2 siblings:
3.405229 - .026787*2 + .130127
```

:::

<br>

::: {.fragment}

```{r}
#| echo: true
#| output-location: fragment

# For upper middle class student with 1 sibling:
3.405229 -  .026787*1 + .191764
```

:::

---

## Warm Up 2

```{r}
gpa_sibs_plot + geom_point(color = "Light Gray") + 
     geom_abline(intercept = 3.405229, slope = -0.026787, color = "Red") +
     geom_abline(intercept = 3.405229+0.130127, slope = -0.026787, color = "Forest Green") +
     geom_abline(intercept = 3.405229+0.158991, slope = -0.026787, color = "Deep Sky Blue") +
     geom_abline(intercept = 3.405229+0.191764, slope = -0.026787, color = "Purple") +
     geom_text(x = 2.5, y = 4, label = "Upper Middle", color = "Purple", size = 10) +
     geom_text(x = 2.5, y = 3.875, label = "Upper", color = "Deep Sky Blue", size = 10) +
     geom_text(x = 2.5, y = 3.75, label = "Middle", color = "Forest Green", size = 10) +
     geom_text(x = 2.5, y = 3.625, label = "Lower", color = "Red", size = 10) +
     labs(x = "Number of Siblings", y = "GPA", title = "GPA and Number of Siblings", subtitle = "Professor Peggy Nelson's Middlebury Survey") + 
     theme(axis.title = element_text(size = 18), axis.text = element_text(size = 16),
      plot.title = element_text(size = 18), plot.subtitle = element_text(size = 14))
```

---

## Warm Up 3

### Group 3: Add controls for gender and class to original model

::: {.fragment}

```{r}
#| echo: true
#| output: false

gpa_sibs_class_gender_model <- 
lm(gpa ~ siblings + class + gender, data = midd_survey)

summary(gpa_sibs_class_gender_model)
```

:::


---

## Warm Up 3

```{r}
summary(gpa_sibs_class_gender_model)
```

---

## Warm Up 3

### Predict gpa for lower class men with 0 siblings

::: {.fragment}

```{r}
#| echo: true

3.368622
```

:::

---

## Where We Are Now

- We know lines can have different starting points. That means there can be different alphas, or intercepts.

- We know the predicted values on the lines can be different from the observed values. Those differences are the residuals.

---

## Where We Are Now

- One reason we might have big residuals is because we assume that the change for each increase in our X variable is the same for all values of our control variable(s).

- If that is not true, we need a way to let the slopes of our lines vary too.

- More formally, we want to know if the average change in Y for a change in X changes as the value of our control variable changes

---

## We Are About To Move From This...

::: {.fragment}

```{r}
gpa_sibs_plot + geom_point(color = "Light Gray") + 
     geom_abline(intercept = 3.405229, slope = -0.026787, color = "Red") +
     geom_abline(intercept = 3.405229+0.130127, slope = -0.026787, color = "Forest Green") +
     geom_abline(intercept = 3.405229+0.158991, slope = -0.026787, color = "Deep Sky Blue") +
     geom_abline(intercept = 3.405229+0.191764, slope = -0.026787, color = "Purple") +
     geom_text(x = 2.5, y = 4, label = "Upper Middle", color = "Purple", size = 10) +
     geom_text(x = 2.5, y = 3.875, label = "Upper", color = "Deep Sky Blue", size = 10) +
     geom_text(x = 2.5, y = 3.75, label = "Middle", color = "Forest Green", size = 10) +
     geom_text(x = 2.5, y = 3.625, label = "Lower", color = "Red", size = 10) +
     labs(x = "Number of Siblings", y = "GPA", title = "GPA and Number of Siblings", subtitle = "Professor Peggy Nelson's Middlebury Survey") + 
     theme(axis.title = element_text(size = 18), axis.text = element_text(size = 16),
      plot.title = element_text(size = 18), plot.subtitle = element_text(size = 14))
```


:::

---

## To This...

```{r}
gpa_sibs_class_plot <- ggplot(midd_survey, aes(x = siblings, y = gpa, color = class))

gpa_sibs_class_plot + geom_point(color = "Light Gray") + 
     geom_smooth(method = "lm") +
     labs(x = "Number of Siblings", y = "GPA", title = "GPA and Number of Siblings", subtitle = "Professor Peggy Nelson's Middlebury Survey") + 
     theme(legend.position = "bottom",
      axis.title = element_text(size = 18), axis.text = element_text(size = 16),
      plot.title = element_text(size = 18), plot.subtitle = element_text(size = 14))
```

---

## Introducing Interactions

- An interaction is the product of two (or more) variables.

- When we wanted to add another control variable, we used a plus sign:

::: {.fragment}

```{r}
#| echo: true
#| output: false

gpa_sibs_class_model <- lm(gpa ~ siblings + class, 
      data = midd_survey)
```

:::

- When we want to include the product of two variables, we use a star:

::: {.fragment}

```{r}
#| echo: true
#| output: false

gpa_sibsXclass_model <- 
lm(gpa ~ siblings * class, 
      data = midd_survey)

summary(gpa_sibsXclass_model)
```

:::

---

## Introducing Interactions

```{r}
summary(gpa_sibsXclass_model)
```

---

## Introducing Interactions

- This model has *main effects*: Siblings, Middle Class, Upper Class, Upper Middle Class

- And it has *interaction effects*: Siblings X Middle Class, Siblings X Upper Class, and Siblings X Upper Middle Class

- The interaction term tells us how the slope varies for each value of the other variable.

- The slope for our reference group (Lower Class) is the coefficient for siblings: -0.09065

---

## Introducing Interactions

```{r}
summary(gpa_sibsXclass_model)
```

---

## Introducing Interactions

- The slope for our other groups is the coefficient for siblings plus the respective interaction term

- For Middle Class:
  - -0.09065 + 0.09276 = 0.00211

- For Upper Class:
  - -0.09065 + 0.08201 =  -0.00864

- For Upper Middle Class:
  - -0.09065 + 0.08165 = -0.009

---

## Interactions and Predictions

- For predictions, use the full equation

::: {.fragment}

```{r}
#| echo: true
#| eval: false

3.52009 - 0.09065*(siblings) - 0.02612*(middle class) + 
0.01418*(upper class) +0.05007*(upper middle class) + 
0.09276*(siblings*middle class) +
0.08201*(siblings*upper class) + 
0.08165*(siblings*upper middle class)
```

:::

- This still makes the intercept the predicted gpa for a lower class student with zero siblings:

::: {.fragment}

```{r}
3.52009 - 0.09065*(0) - 0.02612*(0) + 0.01418*(0) +
0.05007*(0) + 0.09276*(0) + 0.08201*(0) + 0.08165*(0)
```

:::

---

## Interactions and Predictions

- Without interactions, we estimated the predicted gpa for a middle class student with 2 siblings to be 3.481782.

- What is the prediction with interactions?

::: {.fragment}

```{r}
#| echo: true
#| ouput-location: fragment

3.52009 - 0.09065*(2) - 0.02612*(1) + 0.01418*(0) +
0.05007*(0) + 0.09276*(2*1) + 0.08201*(2*0) + 0.08165*(2*0)
```

:::

---

## Plotting Interactions

- Add your control variable to the aesthetics map as the color. The regular `geom_smooth(method = lm)` function includes interactions by default.

::: {.fragment}

```{r}
#| echo: true
#| output: false

gpa_sibs_class_plot <- ggplot(midd_survey, 
      aes(x = siblings, y = gpa, color = class))

gpa_sibs_class_plot + geom_point(color = "Light Gray") + 
     geom_smooth(method = lm) +
     labs(x = "Number of Siblings", y = "GPA", 
      title = "GPA and Number of Siblings", 
      subtitle = "Professor Peggy Nelson's Middlebury Survey") + 
     theme(legend.position = "bottom")
```

:::

---

## Plotting Interactions

```{r}
gpa_sibs_class_plot <- ggplot(midd_survey, aes(x = siblings, y = gpa, color = class))

gpa_sibs_class_plot + geom_point(color = "Light Gray") + 
     geom_smooth(method = lm) +
     labs(x = "Number of Siblings", y = "GPA", title = "GPA and Number of Siblings", subtitle = "Professor Peggy Nelson's Middlebury Survey") + 
     theme(legend.position = "bottom",
      axis.title = element_text(size = 18), axis.text = element_text(size = 16),
      plot.title = element_text(size = 18), plot.subtitle = element_text(size = 14))
```

---

## Understanding Interactions

- Interactions are not always significant! If *none* are significant, do not use that model (usually).

- Have to include the *main effects* when you have an interaction. R does this automatically; other programs do not.

- If the main effects are not significant when you add the interactions but the interactions are significant, that's okay.

- With lots of interactions, can be hard to imagine a plot...much easier to calculate predictions when you have interactions.


---

## Understanding Interactions

- Key takeaway is that a significant interaction effect tells you that the change for a one unit change in X is different for at least one value of another variable. That means the slope varies.

---

## Interactions - Example 2

- Our questions before interactions: On a scale from 1-5, would you expect students to disagree or agree that they are actively looking to start a relationship at Middlebury (`midd_lookingfor_relationship`)? 

  - Will the average responses vary across genders? Would school year explain that variation?

- Our question with interactions: Would you expect any differences across genders to vary by school year?

::: {.fragment}

```{r}
# Let's order year before we continue...
midd_survey <- mutate(midd_survey, year = factor(year,
     levels = c("First Year", "Sophomore", 
      "Junior", "Senior")))
```

:::

---

## Example 2 - The Basic Model

### Start with the bivariate relationship

::: {.fragment}

```{r}
#| echo: true
#| output: false

lookrel_gender_model <- 
     lm(midd_lookingfor_relationship ~ gender, 
      data = midd_survey)

summary(lookrel_gender_model)
```

:::

---

## Example 2 - Basic Model

```{r}
summary(lookrel_gender_model)
```

---

## Example 2 - Basic Model

- On average, women's responses tend to be lower than men's responses, meaning women are less likely than men to say they are looking to start a relationship at Middlebury. This difference is significant.

- Students in the other gender category also tend to have lower responses than men, on average. But this difference is not significant.

---

## Example 2 - Control Variable

### Control for year

::: {.fragment}

```{r}
#| echo: true
#| output: false

lookrel_gender_year_model <- 
lm(midd_lookingfor_relationship ~ gender + year, 
      data = midd_survey)

summary(lookrel_gender_year_model)
```

:::

---

## Example 2 - Control Variable

```{r}
summary(lookrel_gender_year_model)
```


---

## Example 2 - Control Variable

- Controlling for school year, average scores for women are still significantly lower than average scores for men.

- Holding gender constant, average scores for seniors are significantly lower than average sores for first year students.

---

## Interactions - Example 2 - Full Model

### Add interaction between gender and year

::: {.fragment}

```{r}
#| echo: true
#| output: false

lookrel_genderXyear_model <- 
lm(midd_lookingfor_relationship ~ gender * year, 
data = midd_survey)

summary(lookrel_genderXyear_model)
```

:::

---

## Interactions - Example 2 - Full Model

```{r}
summary(lookrel_genderXyear_model)
```

---

## Interpreting - Example 2 - Full Model

- The difference between seniors and first years is .48 points lower for women than it is for men, on average. This difference is significant.

- Among sophomores, average scores for students in the other gender category are 3.26 points higher than the average scores for men. This difference is significant.

---

## Summarizing Interactions

- With lots of variables, interpreting and plotting interactions can get messy.

- Easier to predict values from your full model and describe them.

- Remember the `fitted.values` function can calculate predictions and save them as a new variable:

::: {.fragment}

```{r}
#| echo: true

midd_survey$pred_lookrel <- 
  lookrel_genderXyear_model$fitted.values
```

:::

---

## Summarizing Interactions

- Then use `group_by()` and `summarize()` to describe the predictions for each combination of the variables you are interacting

- We'll also assert the order of the class years

::: {.fragment}

```{r}
#| echo: true
#| output: false

lookrel_predictions <- midd_survey |>
    mutate(year = factor(year,
                       levels = c("First Year",
                                  "Sophomore",
                                  "Junior",
                                  "Senior"))) |> 
     group_by(gender, year) |>
     summarize(agree_look_rel = round(mean(pred_lookrel),3))
```

:::

---

## Summarizing Predictions

```{r}
#| echo: true
#| output-location: fragment

kbl(lookrel_predictions,
    booktabs = TRUE,
    align = rep("c", 2))
```


---

## Summarizing Predictions

```{r}
#| echo: true
#| output-location: fragment

lookrel_predictions |> 
  pivot_wider(names_from = "year", values_from = "agree_look_rel") |>
  kbl(booktabs = TRUE,
    align = rep("c", 4)) |> 
  kable_paper()
```